---
title: "Weissman-replication-analysis"
author: "Marton Kovacs"
date: '`r format(Sys.time(), "%d %B, %Y")`'
output: html_document
---

# Load packages

```{r load packages}
library(tidyverse)
library(osfr)
library(lme4)
library(BayesFactor)
library(DescTools)
library(sjstats)
```

# Load helper functions

```{r load helper functions}
source("utils.R")
```

# Download data from OSF
## OSF auth (until project is public)
osf_auth(token = read_lines("osf_token_write_martonbalazskovacs.txt"))
```{r osf authentication}
```

## Connect to data OSF folder
```{r osf connect to OSF folder}
data_guid <- "9knds"

weissman_project <- osf_retrieve_node(data_guid)
```

## Download data locally

```{r osf download data}
local_data_pth <- file.path("data","Processed")

create_local_structure(local_data_pth)

data_files <- 
  weissman_project %>% 
  osf_ls_files() %>% 
  filter(name == "Processed") %>% 
  osf_ls_files() 

data_files %>% 
  group_by(name) %>% # for each experiment type
  do(download_files(.,local_data_pth))

# uncomment following line to remove the data   
# remove_local_data(local_data_pth)
```

# Import data

```{r}
# Saving subfolder names
subfolder <- list("primeprobe", "flanker", "stroop", "simon")

# Reading in data
processed <-
  tibble(task = subfolder,
         rt_data = map(subfolder,
                       ~ read_plus(subfolder_name = .x,
                                   pattern = ".tsv$",
                                   path = "data/Processed/",
                                   sep = "\t",
                                   exclude = "_Acc_")),
         acc_data = map(subfolder,
                        ~ read_plus(subfolder_name = .x,
                                    pattern = ".tsv$",
                                    path = "data/Processed/",
                                    sep = "\t",
                                    exclude = "_RT_")))
```

# Descriptive statistics of the sample size

```{r}
# Number of participants left after exclusion
## The number of participants is the same for the reaction time and accuracy analysis as well

map(processed$rt_data,
    . %>% 
      distinct(participant_id) %>% 
      count())

# Number of responses after exclusion
## For the reaction time analysis

map(processed$rt_data,
    . %>% 
      count())

## For the accuracy analysis

map(processed$acc_data,
    . %>% 
      count())

# Age

map(processed$rt_data,
    . %>% 
      distinct(participant_id, .keep_all = T) %>% 
      summarize(median_age = median(age, na.rm = T),
                min_age = min(age, na.rm = T),
                max_age = max(age, na.rm = T),
                quart1_age = quantile(age, probs = 0.25, na.rm = T),
                quart3_age = quantile(age, probs = 0.75, na.rm = T)) %>% 
      knitr::kable(caption = "Age demogrpahics"))

# Gender

map(processed$rt_data,
    . %>% 
      distinct(participant_id, .keep_all = T) %>% 
      group_by(gender) %>% 
      count() %>% 
      ungroup() %>% 
      filter(gender %in% c("female", "male")) %>% 
      mutate(prop = n / sum(n) * 100) %>% 
      knitr::kable(caption = "Gender demogrpahics"))

# Language

map(processed$rt_data,
    . %>% 
      distinct(participant_id, .keep_all = T) %>% 
      mutate(loc = case_when(loc == "HUN" ~ "Hungarian",
                             loc == "CZ" ~ "Czech")) %>% 
      group_by(loc) %>% 
      count() %>% 
      ungroup() %>% 
      mutate(prop = n / sum(n) * 100) %>% 
      knitr::kable(caption = "Language demogrpahics"))

# Education demographics

map(processed$rt_data,
    . %>% 
      distinct(participant_id, .keep_all = T) %>% 
      group_by(education) %>% 
      count() %>% 
      ungroup() %>% 
      filter(education %ni% c("blank", "refused")) %>% 
      mutate(prop = n / sum(n) * 100) %>% 
      knitr::kable(caption = "Education demogrpahics"))
```

# Figures of CSE

```{r}
processed <-
  processed %>% 
  mutate(cse_plot_data = map(rt_data,
                             . %>% 
                               mutate(isPrevCongruent = case_when(isPrevCongruent ==  0L ~ "Incongruent",
                                                                  isPrevCongruent ==  1L ~ "Congruent"),
                                      isCongruent = case_when(isCongruent ==  0L ~ "Incongruent",
                                                              isCongruent ==  1L ~ "Congruent")) %>% 
                               group_by(isPrevCongruent, isCongruent) %>% 
                               summarise(N = n(),
                                         mean_rt = mean(rt, na.rm = T),
                                         sd_rt = sd(rt, na.rm = T),
                                         se_rt = sd_rt / sqrt(N))),
         cse_plot = map(cse_plot_data,
                        ~ ggplot(.x, aes(x = isPrevCongruent, y = mean_rt, shape = isCongruent, group = isCongruent)) +
                          geom_path() +
                          geom_point() +
                          geom_errorbar(aes(ymin = mean_rt - se_rt, ymax = mean_rt + se_rt), width=.1) +
                          xlab("Congruency of the previous trial")+
                          ylab("Reaction time") +
                          guides(shape = guide_legend(title="Congruency of \n the current trial"))
                        ))
```

# Reaction time analyis
## Calculate mean reaction time for the analysis for each participant in each task

### TODO: Clean this mess up

```{r calculating mean dev}
processed <-
  processed %>% 
  mutate(rt_data = map(rt_data,
                       . %>% 
                         group_by(participant_id, isCongruent, isPrevCongruent) %>% 
                         summarise(rtConditionalMean = mean(rt, na.rm = T)) %>% 
                         ungroup() %>% 
                         mutate(condition = case_when(isPrevCongruent == 0L & isCongruent == 0L ~ "ii",
                                                      isPrevCongruent == 0L & isCongruent == 1L ~ "ic",
                                                      isPrevCongruent == 1L & isCongruent == 0L ~ "ci",
                                                      isPrevCongruent == 1L & isCongruent == 1L ~ "cc",
                                                      TRUE ~ NA_character_)) %>% 
                         select(-isPrevCongruent, -isCongruent) %>% 
                         spread(key = condition, value = rtConditionalMean) %>% 
                         mutate(congruencyEffect = ((ci + ii) / 2) - ((cc + ic) / 2),
                                cseEffect = (ci - cc) - (ii - ic))))
```

## Running confirmatory analysis

```{r}
processed <-
  processed %>% 
  mutate(anova_rt = map(rt_data,
                        ~ aov(rtConditionalMean ~ isCongruent *isPrevCongruent + Error(participant_id/(isCongruent*isPrevCongruent)), data = .x)),
         anova_rt_eta = map(anova_rt,
                            ~ eta_sq(.x, partial = TRUE) %>% 
                              filter(stratum == "participant_id:isCongruent:isPrevCongruent") %>% 
                              pull(partial.etasq)))
```

### Calculating Bayes factors

```{r}
processed <-
  processed %>% 
  mutate(bf_rt = map(anova_rt,
                     ~ Bf()))
```

## Correlation analysis

```{r}
processed <-
  processed %>% 
  mutate(corr = map(rt_data,
                    ~ cor.test(.x$congruencyEffect, .x$cseEffect, method = "spearman")))
```

## Interaction between tasks
### Creating the datatable

```{r}
interaction_rt_data <- 
  processed %>% 
  mutate(interaction_data = map2(rt_data, task, ~ .x %>% mutate(task = .y))) %>% 
  unnest(interaction_data)
```

### Running the analysis

```{r}

```

# Accuracy analysis
## Calculate mean accuracy for the analysis for each participant in each task

```{r calculating mean dev}
processed <-
  processed %>% 
  mutate(acc_data = map(acc_data,
                        . %>% 
                          group_by(participant_id, isCongruent, isPrevCongruent) %>% 
                          summarise(AccConditionalMean = mean(isCorrect, na.rm = T)) %>% 
                          ungroup() %>% 
                          mutate(isCongruent = as_factor(isCongruent),
                                 isPrevCongruent = as_factor(isPrevCongruent),
                                 participant_id = as_factor(participant_id))))
```

## Running confirmatory analysis

```{r}
processed <-
  processed %>% 
  mutate(anova_acc = map(acc_data,
                        ~ aov(AccConditionalMean ~ isCongruent *isPrevCongruent + Error(participant_id/(isCongruent*isPrevCongruent)), data = .x)),
         anova_acc_eta = map(anova_acc,
                            ~ eta_sq(.x, partial = TRUE) %>% 
                              filter(stratum == "participant_id:isCongruent:isPrevCongruent") %>% 
                              pull(partial.etasq)))
```


---
title: "Weissman-replication-analysis"
author: "Marton Kovacs"
date: '`r format(Sys.time(), "%d %B, %Y")`'
output: html_document
---

# Load packages

```{r load packages}
library(tidyverse)
library(osfr)
library(lme4)
library(BayesFactor)
library(DescTools)
library(sjstats)
library(car)
library(broom)
```

# Load helper functions

```{r load helper functions}
source("utils.R")
```

# Download data from OSF
## OSF auth (until project is public)
osf_auth(token = read_lines("osf_token_write_martonbalazskovacs.txt"))
```{r osf authentication}
```

## Connect to data OSF folder
```{r osf connect to OSF folder}
data_guid <- "9knds"

weissman_project <- osf_retrieve_node(data_guid)
```

## Download data locally

```{r osf download data}
local_data_pth <- file.path("data","Processed")

create_local_structure(local_data_pth)

data_files <- 
  weissman_project %>% 
  osf_ls_files() %>% 
  filter(name == "Processed") %>% 
  osf_ls_files() 

data_files %>% 
  group_by(name) %>% # for each experiment type
  do(download_files(.,local_data_pth))

# uncomment following line to remove the data   
# remove_local_data(local_data_pth)
```

# Import data

```{r}
# Saving subfolder names
subfolder <- list("primeprobe", "flanker", "stroop", "simon")

# Reading data
processed <-
  tibble(task = subfolder,
         rt_data = map(subfolder,
                       ~ read_plus(subfolder_name = .x,
                                   pattern = ".tsv$",
                                   path = "data/Processed/",
                                   sep = "\t",
                                   exclude = "_Acc_")),
         acc_data = map(subfolder,
                        ~ read_plus(subfolder_name = .x,
                                    pattern = ".tsv$",
                                    path = "data/Processed/",
                                    sep = "\t",
                                    exclude = "_RT_")))

# Reading original study effect sizes
original <- read_tsv("original_study_data.tsv")
```

# Descriptive statistics of the sample size
## Number of participants left after exclusion

The number of participants is the same for the reaction time and accuracy analysis as well

```{r}
map(processed$rt_data,
    . %>% 
      distinct(participant_id) %>% 
      count())
```

## Number of responses after exclusion
### For the reaction time analysis

```{r}
map(processed$rt_data,
    . %>% 
      count())
```

### For the accuracy analysis

```{r}
map(processed$acc_data,
    . %>% 
      count())
```

## Age

We calculated the following statistics based on the reaction time data file, but because it contains the same participants as the accuracy data file there should be no difference between the results.

```{r}
map(processed$rt_data,
    . %>% 
      distinct(participant_id, .keep_all = T) %>% 
      summarize(median_age = median(age, na.rm = T),
                min_age = min(age, na.rm = T),
                max_age = max(age, na.rm = T),
                quart1_age = quantile(age, probs = 0.25, na.rm = T),
                quart3_age = quantile(age, probs = 0.75, na.rm = T)) %>% 
      knitr::kable(caption = "Age demogrpahics"))
```

## Gender

```{r}
map(processed$rt_data,
    . %>% 
      distinct(participant_id, .keep_all = T) %>% 
      group_by(gender) %>% 
      count() %>% 
      ungroup() %>% 
      filter(gender %in% c("female", "male")) %>% 
      mutate(prop = n / sum(n) * 100) %>% 
      knitr::kable(caption = "Gender demogrpahics"))
```

## Language

```{r}
map(processed$rt_data,
    . %>% 
      distinct(participant_id, .keep_all = T) %>% 
      mutate(loc = case_when(loc == "HUN" ~ "Hungarian",
                             loc == "CZ" ~ "Czech")) %>% 
      group_by(loc) %>% 
      count() %>% 
      ungroup() %>% 
      mutate(prop = n / sum(n) * 100) %>% 
      knitr::kable(caption = "Language demogrpahics"))
```

## Education demographics

```{r}
map(processed$rt_data,
    . %>% 
      distinct(participant_id, .keep_all = T) %>% 
      group_by(education) %>% 
      count() %>% 
      ungroup() %>% 
      filter(education %ni% c("blank", "refused")) %>% 
      mutate(prop = n / sum(n) * 100) %>% 
      knitr::kable(caption = "Education demogrpahics"))
```

# Figures of CSE
## For the reaction time data

```{r}
processed <-
  processed %>% 
  mutate(cse_plot_rt_data = map(rt_data,
                                . %>% 
                                  mutate(isPrevCongruent = case_when(isPrevCongruent ==  0L ~ "Incongruent",
                                                                     isPrevCongruent ==  1L ~ "Congruent"),
                                         isCongruent = case_when(isCongruent ==  0L ~ "Incongruent",
                                                                 isCongruent ==  1L ~ "Congruent")) %>%
                                  group_by(isPrevCongruent, isCongruent) %>% 
                                  summarise(N = n(),
                                            mean_rt = mean(rt, na.rm = T),
                                            sd_rt = sd(rt, na.rm = T),
                                            se_rt = sd_rt / sqrt(N))),
         cse_plot_rt = map(cse_plot_rt_data,
                           ~ ggplot(.x, aes(x = isPrevCongruent, y = mean_rt, shape = isCongruent, group = isCongruent)) +
                             geom_path() +
                             geom_point() +
                             geom_errorbar(aes(ymin = mean_rt - se_rt, ymax = mean_rt + se_rt), width=.1) +
                             xlab("Congruency of the previous trial")+
                             ylab("Reaction time") +
                             guides(shape = guide_legend(title="Congruency of \n the current trial"))))
```

## For the accuracy data

```{r}
processed <-
  processed %>% 
  mutate(cse_plot_acc_data = map(acc_data,
                                . %>% 
                                  mutate(isPrevCongruent = case_when(isPrevCongruent ==  0L ~ "Incongruent",
                                                                     isPrevCongruent ==  1L ~ "Congruent"),
                                         isCongruent = case_when(isCongruent ==  0L ~ "Incongruent",
                                                                 isCongruent ==  1L ~ "Congruent")) %>%
                                  group_by(isPrevCongruent, isCongruent) %>% 
                                  summarise(N = n(),
                                            mean_acc = mean(isCorrect, na.rm = T),
                                            sd_acc = sd(isCorrect, na.rm = T),
                                            se_acc = sd_acc / sqrt(N))),
         cse_plot_acc = map(cse_plot_data,
                           ~ ggplot(.x, aes(x = isPrevCongruent, y = mean_acc, shape = isCongruent, group = isCongruent)) +
                             geom_path() +
                             geom_point() +
                             geom_errorbar(aes(ymin = mean_acc - se_acc, ymax = mean_acc + se_acc), width=.1) +
                             xlab("Congruency of the previous trial")+
                             ylab("Reaction time") +
                             guides(shape = guide_legend(title="Congruency of \n the current trial"))))
```

# Reaction time analyis
## I. analysis: Testing whether the CSE was present in the different tasks
### Preprocessing data

We are calculating mean reaction time for the analysis for each participant in each condition for each task.

```{r calculating mean dev}
processed <-
  processed %>% 
  mutate(rt_data = map(rt_data,
                       . %>% 
                         group_by(participant_id, isCongruent, isPrevCongruent) %>% 
                         summarise(rtConditionalMean = mean(rt, na.rm = T)) %>%
                         ungroup() %>% 
                         mutate(isCongruent = as.factor(isCongruent),
                                isPrevCongruent = as.factor(isPrevCongruent),
                                participant_id = as.factor(participant_id))))
```

We are calculating the main congruency effect of the current (n) trial, the main congruency effect of the previous trial (n-1) and the interaction effect (CSE) between them for each participant.

```{r}
processed <-
  processed %>% 
  mutate(rt_effect_data = map(rt_data,
                              . %>% 
                                ungroup() %>% 
                                mutate(condition = case_when(isPrevCongruent == 0L & isCongruent == 0L ~ "ii",
                                                             isPrevCongruent == 0L & isCongruent == 1L ~ "ic",
                                                             isPrevCongruent == 1L & isCongruent == 0L ~ "ci",
                                                             isPrevCongruent == 1L & isCongruent == 1L ~ "cc",
                                                             TRUE ~ NA_character_)) %>% 
                                select(-isPrevCongruent, -isCongruent) %>% 
                                spread(key = condition, value = rtConditionalMean) %>% 
                                mutate(congruencyEffect = ((ci + ii) / 2) - ((cc + ic) / 2),
                                       prevCongruencyEffect = ((ci + cc) / 2) - ((ii + ic) / 2),
                                       cseEffect = (ci - cc) - (ii - ic))))
```

### Running the analysis

We are running a 2 Ã— 2 repeated-measures ANOVA per task with mean RT as dependent variable. The two factors of the ANOVA are Previous Trial Congruency (congruent, incongruent) and Current Trial Congruency (congruent, incongruent).

```{r}
processed <-
  processed %>% 
  mutate(anova_rt = map(rt_data,
                        ~ aov(rtConditionalMean ~ isCongruent * isPrevCongruent + Error(participant_id / (isCongruent * isPrevCongruent)), data = .x)))

processed <-
  processed %>% 
  mutate(t_rt = map(rt_effect_data,
                    ~ t.test(.x$congruencyEffect, mu = 0)))
```

The interaction was only significant for the first task, the primeprobe task.

We are calculating the partial eta square as an effect size estimate for the ANOVA.

```{r}
processed <-
  processed %>% 
  mutate(anova_rt_eta = map(anova_rt,
                            ~ eta_sq(.x, partial = TRUE)))
```

### Calculating Bayes factors
#### Preprocessing data for the Bayes factor analysis

We are substracting the F values for each effect (main congruency effect of current trial, main congruency effect of previous trial and interaction effect) from the ANOVA.

```{r}
processed <-
  processed %>% 
  mutate(anova_rt_f = map(anova_rt,
                          . %>%
                            broom::tidy() %>% 
                            select(term, statistic) %>% 
                            transmute(term = case_when(term == "isCongruent" ~ "mainEffectIsCongruent",
                                                       term == "isPrevCongruent" ~ "mainEffectIsPrevCongruent",
                                                       term == "isCongruent:isPrevCongruent" ~ "interactionEffect",
                                                       term == "Residuals" ~ term),
                                      fValue = statistic) %>% 
                            filter(!is.na(fValue))))
```

We are calculating the mean effects (main congruency effect of current trial, main congruency effect of previous trial and interaction effect) for each task.

```{r}
processed <-
  processed %>% 
  mutate(anova_rt_raw_effect = map(rt_effect_data, 
                                   . %>% 
                                     summarise(mainEffectIsCongruent = mean(congruencyEffect, na.rm = T),
                                               mainEffectIsPrevCongruent = mean(prevCongruencyEffect, na.rm = T),
                                               interactionEffect = mean(cseEffect, na.rm = T),
                                               nParticipant = n()) %>%
                                     gather(key = "term", value = "rawEffect", -nParticipant)))
```

We are adding the calucalted F-values for each effect to the calculated mean effects.


```{r}
processed <-
  processed %>% 
  mutate(anova_rt_raw_effect = map2(anova_rt_raw_effect, anova_rt_f,
                                    ~ inner_join(.x, .y, by = "term")))
```

Calculating the SEs.

```{r}
processed <- 
  processed %>% 
  mutate(anova_rt_raw_effect = map(anova_rt_raw_effect,
                                   . %>% 
                                     mutate(se = rawEffect / sqrt(fValue))))
```

Preprocessing effect sizes that Weissman et al. (2014) found for the H1 model of the Bayes factor analysis.

```{r}
original_rt_effect <-
  original %>% 
  filter(measure == "rt") %>% 
  select(task, congruency, cse) %>% 
  gather(key = "term", value = "originalRawEffect", -task) %>%
  mutate(term = case_when(term == "congruency" ~ "mainEffectIsCongruent",
                          term == "cse" ~ "interactionEffect")) %>% 
  group_by(task) %>% 
  nest() %>% 
  rename(original_effect_reaction_time = data)
```

Joining the effect sizes of the replicated study with the effect sizes of the current study.

```{r}
processed <-
  processed %>%
  mutate(task = as.character(task)) %>% # vector needs to be character class (instead of a list) for joining
  left_join(., original_rt_effect, by = "task") %>% 
  mutate(anova_rt_bf_effect = map2(anova_rt_raw_effect, original_effect_reaction_time,
                              ~ left_join(.x, .y, by = "term")))
```

#### Calculating the Bayes factor
##### For the interaction effect

A half-normal distribution is used with a mode of 0 and a SD equal to the half of the congruency effect (in ms) for the particular task in the original data set by Weissman et al. (2014) to model the prediction of the interaction effect. 

```{r}
processed <-
  processed %>%
  mutate(bf_interaction_rt = map(anova_rt_bf_effect,
                                 ~ Bf(sd = .x$se[3],
                                      obtained = .x$rawEffect[3],
                                      dfdata = .x$nParticipant[1] - 1,
                                      meanoftheory = 0,
                                      sdtheory = .x$originalRawEffect[1] / 2,
                                      dftheory = 10^10,
                                      tail = 1)))
```

##### For the main congruency effect of the current trial

To test the congruency main effect, the SD of the H1 model is set to the congruency effect reported by Weissman et al. (2014) for the given task. The other settings stay the same.

```{r}
processed <-
  processed %>%
  mutate(bf_congruency_rt = map(anova_rt_bf_effect,
                                ~ Bf(sd = .x$se[1],
                                     obtained = .x$rawEffect[1],
                                     dfdata = .x$nParticipant[1] - 1,
                                     meanoftheory = 0,
                                     sdtheory = .x$originalRawEffect[1],
                                     dftheory = 10^10,
                                     tail = 1))) 
```

### Follow up simple effects analysis
#### Preprocessing data

Saving the data of the task (primeprobe) with significant interaction between current trial congruency and previous trial congruency.

```{r}
primeprobe <- processed$rt_effect_data[[1]]
```

#### Running the analysis

If the Bayes factor is greater than the preset threshold of B = 3 for the interaction effect in a given task we run a simple effects analyses, contrasting post-congruent congruent (cC) and post-incongruent congruent (iC) trials.

```{r post congruent follow up comparison}
post_congruent <- 
  t.test(primeprobe$ic, primeprobe$cc, paired = TRUE) %>% 
  broom::tidy()
```

Post-congruent incongruent (cI) and post-incongruent incongruent (iI) trials in another.

```{r post incongruent follow up comparison}
post_incongruent <- 
  t.test(primeprobe$ci, primeprobe$ii, paired = TRUE) %>% 
  broom::tidy()
```

#### Calculating the Bayes factor for the follow up analysis

The prior H1 model is a half-normal distribution with a mode of 0 and an SD equal to half of the CSE estimate for that given task, i.e., the originally reported congruency effect divided by four.

```{r post congruent Bf follow up comparison}
Bf(sd = ,
   obtained = ,
   dfdata = ,
   meanoftheory = 0,
   sdtheory = ,
   dftheory = 10^10,
   tail = 1)
```

The Bayes factor shows

```{r post incongruent Bf follow up comparison}
Bf(sd = ,
   obtained = ,
   dfdata = ,
   meanoftheory = 0,
   sdtheory = ,
   dftheory = 10^10,
   tail = 1)
```

## II. analysis: Testing whether the size of the CSE varies across tasks
### Creating the datatable

We are combining the effects (main congruency effect of current trial, main congruency effect of previous trial and interaction effect) for each task (primeprobe, Flanker, Stroop, Simon) in one datatable.

```{r, warning = FALSE}
interaction_rt_data <- 
  processed %>% 
  mutate(interaction_data = map2(rt_effect_data, task,
                                 ~ .x %>%
                                   mutate(task = .y))) %>% 
  unnest(interaction_data) %>% 
  mutate(task = as.factor(task))
```

### Testing the assumptions

We are testing the homogenity of variances.

```{r}
car::leveneTest(cseEffect ~ task, data = interaction_rt_data)
```

The assumption of homogenity of variances is violated. Therefore, we are running a Kruskal Wallis H test instead of an ANOVA. 

### Running the analysis

We are running a  Kruskal-Wallis H test with task (levels: Prime-Probe, Flanker, Stroop, Simon) as the single factor, and the CSE index as the dependent variable to examine if the size of the effect differs across tasks.

```{r}
kruskal.test(cseEffect ~ task, data = interaction_rt_data)
```

### Calculating pairwise comparisons

A Dunnâ€™s test is used for pairwise comparisons.

```{r}

```

#### Bf analysis of pairwise comparisons

A half-normal distribution is used with a mode of 0 and SD equal to half of the greater congruency effect of the two in any given pair as reported by Weissman et al. (2014).

Tasks in a descending order based on their congruency effect according to the original study:
Stroop > Primeprobe > Flanker > Simon

```{r}

```

## III. analysis: Testing whether the size of the CSE changes as a function of the magnitude of interference

We are calculating correlations between the CSE index and the congruency effect for each task.

```{r}
processed <-
  processed %>% 
  mutate(corr = map(rt_effect_data,
                    ~ cor.test(.x$congruencyEffect, .x$cseEffect, method = "pearson") %>% 
                      broom::tidy()))
```

### Calculating Bayes factors
#### Preprocessing data for the Bayes factor analysis

Preprocessing correlation coefficients that Weissman et al. (2014) found for the H1 model of the Bayes factor analysis.

```{r}
original_corr_effect <- 
  original %>% 
  filter(measure == "rt") %>% 
  select(task, corr) %>% 
  rename(original_corr_estimate = corr)
```

We are Fisher's z transforming the correlation coefficient and calculating the number of participants and the SE for the specification of the Bf model.

```{r}
processed <-
  processed %>% 
  mutate(corr_bf_effect = map(corr,
                              ~ tibble(estimateFisherZ = DescTools::FisherZ(.x$estimate),
                                       df = .x$parameter,
                                       se = 1 / sqrt(df + 1))))
```

We are joining the original preprocessed effects to the effects of the current study.

```{r}
processed <-
  processed %>% 
  left_join(., original_corr_effect, by = "task") %>% 
  mutate(corr_bf_effect = map2(corr_bf_effect, original_corr_estimate,
                               ~ mutate(.x, originalEstimateFisherZ = DescTools::FisherZ(.y))))
```

#### Running the Bayes factor analysis

A two-tailed normal distribution is used as a prior, with a mode of 0 and a SD of 0.549 (corresponding to an r of 0.5).

```{r}
processed <-
  processed %>% 
  mutate(bf_corr = map(corr_bf_effect,
                     ~ Bf(sd = .x$se,
                          obtained = .x$estimateFisherZ,
                          dfdata = .x$df,
                          meanoftheory = 0,
                          sdtheory = .x$originalEstimateFisherZ,
                          dftheory = 10^10,
                          tail = 1)))
```

# Accuracy analysis
## I. analysis: Testing whether the CSE was present in the different tasks
### Preprocessing data

We are calculating the accuracy for the analysis for each participant in each condition for each task.

```{r calculating mean dev}
processed <-
  processed %>% 
  mutate(acc_data = map(acc_data,
                        . %>% 
                          group_by(participant_id, isCongruent, isPrevCongruent) %>% 
                          summarise(AccConditionalMean = mean(isCorrect, na.rm = T)) %>% 
                          ungroup() %>% 
                          mutate(isCongruent = as_factor(isCongruent),
                                 isPrevCongruent = as_factor(isPrevCongruent),
                                 participant_id = as_factor(participant_id))))
```

We are calculating the main congruency effect of the current (n) trial, the main congruency effect of the previous trial (n-1) and the interaction effect (CSE) between them for each participant.

```{r}
processed <-
  processed %>% 
  mutate(acc_effect_data = map(acc_data,
                              . %>% 
                                ungroup() %>% 
                                mutate(condition = case_when(isPrevCongruent == 0L & isCongruent == 0L ~ "ii",
                                                             isPrevCongruent == 0L & isCongruent == 1L ~ "ic",
                                                             isPrevCongruent == 1L & isCongruent == 0L ~ "ci",
                                                             isPrevCongruent == 1L & isCongruent == 1L ~ "cc",
                                                             TRUE ~ NA_character_)) %>% 
                                select(-isPrevCongruent, -isCongruent) %>% 
                                spread(key = condition, value = AccConditionalMean) %>% 
                                mutate(congruencyEffect = ((ci + ii) / 2) - ((cc + ic) / 2),
                                       prevCongruencyEffect = ((ci + cc) / 2) - ((ii + ic) / 2),
                                       cseEffect = (ci - cc) - (ii - ic))))
```

### Running the analysis

We are running a 2 Ã— 2 repeated-measures ANOVA per task with accuracy as dependent variable. The two factors of the ANOVA are Previous Trial Congruency (congruent, incongruent) and Current Trial Congruency (congruent, incongruent).

```{r}
processed <-
  processed %>% 
  mutate(anova_acc = map(acc_data,
                        ~ aov(AccConditionalMean ~ isCongruent * isPrevCongruent + Error(participant_id / (isCongruent * isPrevCongruent)), data = .x)))
```

None of the interaction effects are significant, therefore we will not run any follow up analysis for the accuracy analysis.

We are calculating the partial eta square as an effect size estimate for the ANOVA.

```{r}
processed <-
  processed %>% 
  mutate(anova_acc_eta = map(anova_acc,
                            ~ eta_sq(.x, partial = TRUE) %>% 
                              filter(stratum == "participant_id:isCongruent:isPrevCongruent")))
```

### Calculating Bayes factors
#### Preprocessing data for the Bayes factor analysis

We are substracting the F values for each effect (main congruency effect of current trial, main congruency effect of previous trial and interaction effect) from the ANOVA.

```{r}
processed <-
  processed %>% 
  mutate(anova_acc_f = map(anova_acc,
                          . %>%
                            broom::tidy() %>% 
                            select(term, statistic) %>% 
                            transmute(term = case_when(term == "isCongruent" ~ "mainEffectIsCongruent",
                                                       term == "isPrevCongruent" ~ "mainEffectIsPrevCongruent",
                                                       term == "isCongruent:isPrevCongruent" ~ "interactionEffect",
                                                       term == "Residuals" ~ term),
                                      fValue = statistic)))
```

We are calculating the mean effects (main congruency effect of current trial, main congruency effect of previous trial and interaction effect) for each task.

```{r}
processed <-
  processed %>% 
  mutate(anova_acc_raw_effect = map(acc_effect_data,
                                   . %>% 
                                     summarise(mainEffectIsCongruent = mean(congruencyEffect, na.rm = T),
                                               mainEffectIsPrevCongruent = mean(prevCongruencyEffect, na.rm = T),
                                               interactionEffect = mean(cseEffect, na.rm = T),
                                               nParticipant = n()) %>%
                                     gather(key = "term", value = "rawEffect", -nParticipant)))
```

We are adding the calucalted F-values for each effect to the calculated mean effects.

```{r}
processed <-
  processed %>% 
  mutate(anova_acc_raw_effect = map2(anova_acc_raw_effect, anova_acc_f,
                                    ~ inner_join(.x, .y, by = "term") %>% 
                                      mutate(se = rawEffect / sqrt(fValue))))
```

Preprocessing effect sizes that Weissman et al. (2014) found for the H1 model of the Bayes factor analysis.

```{r}
original_acc_effect <-
  original %>% 
  filter(measure == "acc") %>% 
  select(task, congruency, cse) %>% 
  gather(key = "term", value = "originalRawEffect", -task) %>%
  mutate(term = case_when(term == "congruency" ~ "mainEffectIsCongruent",
                          term == "cse" ~ "interactionEffect")) %>% 
  group_by(task) %>% 
  nest() %>% 
  rename(original_effect_accuracy = data)
```

Joining the effect sizes of the replicated study with the effect sizes of the current study.

```{r}
processed <-
  processed %>%
  mutate(task = as.character(task)) %>% # vector needs to be character class (instead of a list) for joining
  left_join(., original_acc_effect, by = "task") %>% 
  mutate(anova_acc_bf_effect = map2(anova_acc_raw_effect, original_effect_accuracy,
                              ~ left_join(.x, .y, by = "term")))
```

#### Calculating the Bayes factor
##### For the interaction effect

A half-normal distribution is used with a mode of 0 and a SD equal to the half of the congruency effect (in ms) for the particular task in the original data set by Weissman et al. (2014) to model the prediction of the interaction effect. 

```{r}
processed <-
  processed %>% 
  mutate(bf_interaction_acc = map(anova_acc_bf_effect,
                                 ~ Bf(sd = .x$se[3],
                                      obtained = .x$rawEffect[3],
                                      dfdata = .x$nParticipant[1] - 1,
                                      meanoftheory = 0,
                                      sdtheory = .x$originalRawEffect[1] / 2,
                                      dftheory = 10^10,
                                      tail = 1)))
```

##### For the main congruency effect of the current trial

To test the congruency main effect, the SD of the H1 model is set to the congruency effect reported by Weissman et al. (2014) for the given task. The other settings stay the same.

```{r}
processed <-
  processed %>% 
  mutate(bf_congruency_acc = map(anova_acc_bf_effect,
                                ~ Bf(sd = .x$se[1],
                                     obtained = .x$rawEffect[1],
                                     dfdata = .x$nParticipant[1] - 1,
                                     meanoftheory = 0,
                                     sdtheory = .x$originalRawEffect[1],
                                     dftheory = 10^10,
                                     tail = 1))) 
```